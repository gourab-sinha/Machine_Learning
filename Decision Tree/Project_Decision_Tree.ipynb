{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project Decision Tree.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNZW1HYURVBS0N3V8Pva0PN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gourab-sinha/Machine_Learning/blob/master/Decision%20Tree/Project_Decision_Tree.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGJgkzAOXh-0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load Packages\n",
        "from sklearn import datasets\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3TKbEmj0AJr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Decision Tree Class\n",
        "class DecisionTree:\n",
        "  classes = ['setosa', 'versicolor', 'virginica']\n",
        "  \n",
        "  # Information gain\n",
        "  def __information_gain(self,X,feature):\n",
        "\n",
        "    # Continous values\n",
        "    X_new = X[feature].values\n",
        "    X_new.sort()\n",
        "    total = X.shape[0]\n",
        "    class_with_count = dict(X['target'].value_counts().items())\n",
        "\n",
        "    # Node Entropy\n",
        "    level_entropy = 0\n",
        "    for key,val in class_with_count.items():\n",
        "      level_entropy += (val/total)*math.log2(val/total)\n",
        "    \n",
        "    level_entropy = -level_entropy\n",
        "                      \n",
        "    # Initialize required parameters\n",
        "    max_info_gain = 0\n",
        "    level_threshold = 0\n",
        "    max_gain_ratio = 0\n",
        "\n",
        "    for i in range(1,len(X_new)):\n",
        "      # Define threshold \n",
        "      threshold = (X_new[i-1]+X_new[i])/2\n",
        "      \n",
        "      # Data points below or equal to threshold\n",
        "      X_below_threshold = X[X[feature]<threshold]\n",
        "\n",
        "      # Data points above threshold \n",
        "      X_above_threshold = X[X[feature]>=threshold]\n",
        "\n",
        "\n",
        "      # # Data points below and above\n",
        "      total_below = X_below_threshold.shape[0]\n",
        "      total_above = X_above_threshold.shape[0]\n",
        "      # # print(total_below,total_above)\n",
        "\n",
        "      info_required_below = 0\n",
        "      if total_below>0:\n",
        "        # Indices of target values for below threshold\n",
        "        Y_below = X_below_threshold['target']\n",
        "\n",
        "        class_with_count = dict(Y_below.value_counts().items())\n",
        "\n",
        "        info_required_below = 0\n",
        "        # Information required below threshold\n",
        "        for key,val in class_with_count.items():\n",
        "          info_required_below += (val/total_below)*math.log2(val/total_below)\n",
        "        \n",
        "        info_required_below = -info_required_below\n",
        "      \n",
        "      info_required_above = 0\n",
        "      if total_above>0:\n",
        "        # Indices of target values for above threshold\n",
        "        Y_above = X_above_threshold['target']\n",
        "\n",
        "        class_with_count = dict(Y_above.value_counts().items())\n",
        "\n",
        "        for key,val in class_with_count.items():\n",
        "          info_required_above+= (val/total_above)*math.log2(val/total_above)\n",
        "\n",
        "        info_required_above = -info_required_above\n",
        "\n",
        "      \n",
        "      \n",
        "      # Information required\n",
        "      info_require = (total_below/total)*info_required_below + (total_above/total)*info_required_above\n",
        "\n",
        "      # # Current gain\n",
        "      current_info_gain = level_entropy - info_require\n",
        "\n",
        "      # Split Information\n",
        "      current_split_info = 0 \n",
        "      if total_below>0:\n",
        "        current_split_info += (total_below/total)*math.log2(total_below/total)\n",
        "      if total_above>0:\n",
        "        current_split_info += (total_above/total)*math.log2(total_above/total)\n",
        "      \n",
        "      current_split_info = -current_split_info\n",
        "\n",
        "      # Current Gain Ratio \n",
        "      current_gain_ratio = 0\n",
        "      if current_split_info>0:\n",
        "        current_gain_ratio = current_info_gain/current_split_info\n",
        "      # Check with previous Max Gain Ratio\n",
        "      if max_gain_ratio <= current_gain_ratio :\n",
        "        level_threshold = threshold\n",
        "        max_info_gain  = current_info_gain\n",
        "        max_gain_ratio = current_gain_ratio\n",
        "\n",
        "    \n",
        "    return max_info_gain, max_gain_ratio, level_entropy, level_threshold\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # Decision Tree \n",
        "  def decision_tree(self,X, features,level,targets):  \n",
        "    types = dict(X[targets].value_counts().items())\n",
        "    # print(len(types),len(features))\n",
        "    if len(features)==0 or len(types)==1:\n",
        "      print(\"Level \",level)\n",
        "      for key,val in types.items():\n",
        "        print(\"Count of \",self.classes[key],val)\n",
        "      \n",
        "      entropy = 0\n",
        "      total = X.shape[0]\n",
        "      if total!=0:\n",
        "        for key,val in types.items():\n",
        "          entropy -= (val/total)*math.log2(val/total)\n",
        "      \n",
        "      print(\"Current Entropy is\", entropy)\n",
        "      print(\"Reached leaf Node\")\n",
        "      return \n",
        "    \n",
        "    selected_feature = \"\"\n",
        "    max_info_gain = 0\n",
        "    level_gain_ratio = 0\n",
        "    level_entropy = 0\n",
        "    level_threshold = 0 # for continuous\n",
        "    for feature in features:\n",
        "      gain, gain_ratio, entropy, threshold = self.__information_gain(X,feature)\n",
        "      if gain_ratio>=level_gain_ratio:\n",
        "        selected_feature = feature\n",
        "        max_gain = gain\n",
        "        level_gain_ratio = gain_ratio \n",
        "        level_entropy = entropy\n",
        "        level_threshold = threshold  \n",
        "\n",
        "    \n",
        "    count_with_classes = dict(X[targets].value_counts().items())\n",
        "    print(\"Level \", level)\n",
        "    for key,val in count_with_classes.items():\n",
        "      print(\"Count of \"+self.classes[key],val)\n",
        "    print(\"Current Entropy is \",level_entropy)\n",
        "    print(\"Splitting on feature \"+str(selected_feature)+ \" with gain ratio\",level_gain_ratio)\n",
        "    features.remove(selected_feature)\n",
        "\n",
        "\n",
        "    X1 = X[X[selected_feature]<=level_threshold].copy()\n",
        "    X2 = X[X[selected_feature]>level_threshold].copy()\n",
        "    self.decision_tree(X1,features,level+1,targets)\n",
        "    self.decision_tree(X2,features,level+1,targets)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMVPPT8as5bM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "outputId": "5102640b-8efa-485d-9a74-283187965650"
      },
      "source": [
        "# Load data\n",
        "iris = datasets.load_iris()\n",
        "X = pd.DataFrame(iris.data,columns = iris.feature_names)\n",
        "X['target'] = iris.target\n",
        "features = iris.feature_names\n",
        "\n",
        "# Decision Tree object and function call\n",
        "dc_tree = DecisionTree()\n",
        "dc_tree.decision_tree(X,features,0,\"target\")"
      ],
      "execution_count": 259,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Level  0\n",
            "Count of virginica 50\n",
            "Count of versicolor 50\n",
            "Count of setosa 50\n",
            "Current Entropy is  1.584962500721156\n",
            "Splitting on feature petal width (cm) with gain ratio 0.9999999999999999\n",
            "Level  1\n",
            "Count of setosa 50\n",
            "Count of versicolor 7\n",
            "Current Entropy is  0.5373760853377336\n",
            "Splitting on feature petal length (cm) with gain ratio 1.0\n",
            "Level  2\n",
            "Count of  setosa 50\n",
            "Current Entropy is 0.0\n",
            "Reached leaf Node\n",
            "Level  2\n",
            "Count of  versicolor 7\n",
            "Current Entropy is 0.0\n",
            "Reached leaf Node\n",
            "Level  1\n",
            "Count of virginica 50\n",
            "Count of versicolor 43\n",
            "Current Entropy is  0.9959094138937685\n",
            "Splitting on feature sepal length (cm) with gain ratio 0.9258200994482485\n",
            "Level  2\n",
            "Count of versicolor 43\n",
            "Count of virginica 8\n",
            "Current Entropy is  0.6267511370265895\n",
            "Splitting on feature sepal width (cm) with gain ratio 0.42022930815923804\n",
            "Level  3\n",
            "Count of  versicolor 43\n",
            "Count of  virginica 7\n",
            "Current Entropy is 0.584238811642856\n",
            "Reached leaf Node\n",
            "Level  3\n",
            "Count of  virginica 1\n",
            "Current Entropy is 0.0\n",
            "Reached leaf Node\n",
            "Level  2\n",
            "Count of  virginica 42\n",
            "Current Entropy is 0.0\n",
            "Reached leaf Node\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}