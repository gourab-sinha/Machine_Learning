{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Gradient Descent.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOYuqJlnVWFY4o24b921MrT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gourab-sinha/Machine_Learning/blob/master/Linear%20Regression/Gradient_Descent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFp8qMFPjGK0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQ0z_gEmjQIO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load 1D data\n",
        "data = np.loadtxt('data.csv',delimiter=',')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjXG7b9j0B2j",
        "colab_type": "text"
      },
      "source": [
        "# Gradient Descent Class \n",
        "##### It contains three functions 1. grad access level public 2. step_grad access level private 3. cost access level private\n",
        "###### grad function return the m , c of equation y = m*x + c and it takes three parameters a. data points b. learning_rate c. iteration number\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8iQFG7Gpgdn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Gradient Descent\n",
        "class Gradient_Descent:\n",
        "\n",
        "  def __cost(self, points, m, c):\n",
        "    # No of Data points\n",
        "    N = len(points)\n",
        "    \n",
        "    # Cost\n",
        "    cost = 0\n",
        "\n",
        "    for point in points:\n",
        "      x = point[0]\n",
        "      y = point[1]\n",
        "      cost += (1/N)*((y-x*m+c)**2)\n",
        "\n",
        "    return cost\n",
        "    \n",
        "    \n",
        "\n",
        "\n",
        "  def __step_grad(self, points, learning_rate, m, c):\n",
        "    m_slope = 0\n",
        "    c_slope = 0\n",
        "\n",
        "    # No of data points\n",
        "    N = len(points)\n",
        "    for point in points:\n",
        "      x = point[0]\n",
        "      y = point[1]\n",
        "      m_slope+= (-2/N)*(y-m*x+c)*x\n",
        "      c_slope+= (-2/N)*(y-m*x+c)\n",
        "\n",
        "    # Calculate new m,c\n",
        "    new_m = m - learning_rate*m_slope\n",
        "    new_c = c - learning_rate*c_slope\n",
        "\n",
        "    return new_m, new_c\n",
        "\n",
        "  def grad(self, points, learning_rate, iteration):\n",
        "    m = 0\n",
        "    c = 0\n",
        "    for i in range(iteration):\n",
        "      m, c = self.__step_grad(points, learning_rate, m, c)\n",
        "      print(\"Cost: \",self.__cost(points,m,c))\n",
        "      # print(m,c)\n",
        "\n",
        "    return m,c"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZNz9ILQz-LI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "44365c05-30af-45fc-d831-e9184decc963"
      },
      "source": [
        "gd = Gradient_Descent()\n",
        "m,c = gd.grad(data,0.0001,100)\n",
        "print(m,c)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cost:  1486.719109014127\n",
            "Cost:  458.94800989755436\n",
            "Cost:  199.94539401949055\n",
            "Cost:  134.6756720041105\n",
            "Cost:  118.2274547498771\n",
            "Cost:  114.08246220714838\n",
            "Cost:  113.03793408184157\n",
            "Cost:  112.77473604136395\n",
            "Cost:  112.70843647164159\n",
            "Cost:  112.69175614579677\n",
            "Cost:  112.68758007869287\n",
            "Cost:  112.68655513784239\n",
            "Cost:  112.6863242944869\n",
            "Cost:  112.68629356745731\n",
            "Cost:  112.68631327099897\n",
            "Cost:  112.68634568367159\n",
            "Cost:  112.68638129951329\n",
            "Cost:  112.68641772298167\n",
            "Cost:  112.68645435039026\n",
            "Cost:  112.6864910296071\n",
            "Cost:  112.68652772229464\n",
            "Cost:  112.68656441879146\n",
            "Cost:  112.68660111666293\n",
            "Cost:  112.68663781529551\n",
            "Cost:  112.68667451453462\n",
            "Cost:  112.6867112143413\n",
            "Cost:  112.68674791470576\n",
            "Cost:  112.6867846156254\n",
            "Cost:  112.68682131709963\n",
            "Cost:  112.68685801912852\n",
            "Cost:  112.68689472171188\n",
            "Cost:  112.6869314248497\n",
            "Cost:  112.686968128542\n",
            "Cost:  112.6870048327887\n",
            "Cost:  112.68704153759008\n",
            "Cost:  112.68707824294582\n",
            "Cost:  112.68711494885606\n",
            "Cost:  112.68715165532092\n",
            "Cost:  112.68718836234024\n",
            "Cost:  112.68722506991418\n",
            "Cost:  112.68726177804263\n",
            "Cost:  112.68729848672558\n",
            "Cost:  112.68733519596317\n",
            "Cost:  112.68737190575526\n",
            "Cost:  112.687408616102\n",
            "Cost:  112.6874453270033\n",
            "Cost:  112.68748203845922\n",
            "Cost:  112.68751875046969\n",
            "Cost:  112.68755546303494\n",
            "Cost:  112.68759217615465\n",
            "Cost:  112.68762888982903\n",
            "Cost:  112.68766560405803\n",
            "Cost:  112.68770231884179\n",
            "Cost:  112.68773903418008\n",
            "Cost:  112.68777575007303\n",
            "Cost:  112.68781246652078\n",
            "Cost:  112.68784918352318\n",
            "Cost:  112.68788590108021\n",
            "Cost:  112.68792261919188\n",
            "Cost:  112.68795933785843\n",
            "Cost:  112.68799605707956\n",
            "Cost:  112.68803277685551\n",
            "Cost:  112.68806949718608\n",
            "Cost:  112.68810621807151\n",
            "Cost:  112.68814293951166\n",
            "Cost:  112.68817966150655\n",
            "Cost:  112.68821638405619\n",
            "Cost:  112.68825310716063\n",
            "Cost:  112.6882898308199\n",
            "Cost:  112.68832655503385\n",
            "Cost:  112.68836327980269\n",
            "Cost:  112.6884000051263\n",
            "Cost:  112.6884367310047\n",
            "Cost:  112.68847345743794\n",
            "Cost:  112.68851018442608\n",
            "Cost:  112.68854691196907\n",
            "Cost:  112.68858364006687\n",
            "Cost:  112.68862036871948\n",
            "Cost:  112.68865709792695\n",
            "Cost:  112.6886938276894\n",
            "Cost:  112.68873055800655\n",
            "Cost:  112.68876728887874\n",
            "Cost:  112.68880402030585\n",
            "Cost:  112.68884075228785\n",
            "Cost:  112.68887748482483\n",
            "Cost:  112.68891421791653\n",
            "Cost:  112.68895095156333\n",
            "Cost:  112.68898768576499\n",
            "Cost:  112.68902442052168\n",
            "Cost:  112.68906115583326\n",
            "Cost:  112.68909789169986\n",
            "Cost:  112.68913462812132\n",
            "Cost:  112.68917136509793\n",
            "Cost:  112.68920810262945\n",
            "Cost:  112.68924484071599\n",
            "Cost:  112.68928157935754\n",
            "Cost:  112.68931831855413\n",
            "Cost:  112.68935505830572\n",
            "Cost:  112.68939179861232\n",
            "Cost:  112.68942853947394\n",
            "1.4801781772601874 0.03514954566751497\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}