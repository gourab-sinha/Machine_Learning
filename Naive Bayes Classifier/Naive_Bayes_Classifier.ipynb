{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Naive_Bayes_Classifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNyZJ1RR0dqDrlQqMaKbsO0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gourab-sinha/Machine_Learning/blob/master/Naive%20Bayes%20Classifier/Naive_Bayes_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fx4NQ9OAeOnQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1ZWMcuhealm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NaiveBayesClassifier:\n",
        "  # Train\n",
        "  def train_classifier(self, train_data):\n",
        "\n",
        "    # Different classes in Target\n",
        "    classes = dict(train_data['target'].value_counts().items())\n",
        "\n",
        "    # To store all information\n",
        "    result = {}\n",
        "    for class_type, count in classes.items():\n",
        "\n",
        "      # Extract only data points which are equal to class_type\n",
        "      features = train_data[train_data['target']==class_type]\n",
        "\n",
        "      # Features present in train_data\n",
        "      feature_names = list(features.columns)\n",
        "\n",
        "      # Target is not require hence removed\n",
        "      feature_names.remove('target')\n",
        "      \n",
        "      # To store features and their differnt labels with count\n",
        "      feature_with_counts = {}\n",
        "\n",
        "      for feature_name in feature_names:\n",
        "\n",
        "        # Differnt labels with count for ith feature\n",
        "        categories_in_feature = dict(features[feature_name].value_counts().items())\n",
        "\n",
        "        # To get total count of the ith feature present \n",
        "        total_count = 0\n",
        "        for category,val in categories_in_feature.items():\n",
        "          total_count += val\n",
        "\n",
        "        # Insert new key with name total_count to hold the total_count\n",
        "        categories_in_feature['total_count'] = total_count\n",
        "\n",
        "        # To hold details of ith feature\n",
        "        feature_with_counts[feature_name] = categories_in_feature\n",
        "      \n",
        "      # Count of class that appeared in data points after filteration \n",
        "      feature_with_counts[\"total_count\"] = count\n",
        "\n",
        "      # To hold with class_type which is present in Target.\n",
        "      result[class_type] = feature_with_counts\n",
        "    \n",
        "    # Number of data points in the train_data set\n",
        "    result[\"overall\"] = train_data.shape[0]\n",
        "    return result\n",
        "\n",
        "\n",
        "  def __probability(self, dictionary,X,current_class):\n",
        "\n",
        "    # Summation of P(X=xj/Y=ai)\n",
        "    output = dictionary[current_class]['total_count']/dictionary['overall']  # 4/7\n",
        "\n",
        "    # Features present in dictionary\n",
        "    features = dictionary[current_class].keys()\n",
        "    for feature in features:\n",
        "      if feature=='total_count':\n",
        "        continue\n",
        "      \n",
        "      # Value present in testing data for selected feature\n",
        "      feature_category = X[feature].iloc[0]\n",
        "\n",
        "      # For selected value total count present, default 1 for laplace correction\n",
        "      total_count_category = dictionary[current_class][feature].get(feature_category,1)\n",
        "\n",
        "      # Calculation for the  P(X=x_jth/Y=a_ith)\n",
        "      cal = total_count_category/(dictionary[current_class]['total_count']+len(dictionary[current_class][feature]))\n",
        "      output = output*cal\n",
        "\n",
        "    return output\n",
        "\n",
        "  def __predictSinglePoint(self, dictionary,X):\n",
        "\n",
        "    # Target classes \n",
        "    classes = dictionary.keys()\n",
        "\n",
        "    # To pick best probability and best target class\n",
        "    best_p = -1000\n",
        "    best_class = -1\n",
        "    first_run = True\n",
        "    for current_class in classes:\n",
        "      if current_class=='overall':\n",
        "        continue\n",
        "      \n",
        "      # Get the probability based on the target class\n",
        "      p_current_class = self.__probability(dictionary,X,current_class)\n",
        "\n",
        "      # Update if p_current_class is greater than the best_p\n",
        "      if(first_run or p_current_class>best_p):\n",
        "        best_p = p_current_class\n",
        "        best_class = current_class\n",
        "\n",
        "      # Once best_p and best_class updated make it false\n",
        "      first_run = False\n",
        "    return best_class\n",
        "  \n",
        "  def predict(self,dictionary,X_test,columns):\n",
        "\n",
        "    # Store results\n",
        "    result = []\n",
        "\n",
        "    # Iterate over all test data points\n",
        "    for x in X_test:\n",
        "      x = pd.DataFrame([x],columns=columns)\n",
        "      class_name = self.__predictSinglePoint(dictionary,x)\n",
        "      result.append(class_name)\n",
        "    \n",
        "    return result\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otmCVUg6jvb5",
        "colab_type": "code",
        "outputId": "509bbb33-ff18-4165-d610-56f3a97194df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "data = [[\"Sunny\",\"High\",\"Yes\"],\n",
        "        [\"Sunny\",\"Low\",\"Yes\"],\n",
        "        [\"Overcast\",\"Medium\",\"No\"],\n",
        "        [\"Rainy\",\"High\",\"No\"],\n",
        "        [\"Overcast\",\"High\",\"Dont Know\"],\n",
        "        [\"Rainy\",\"Medium\",\"No\"],\n",
        "        [\"Overcast\",\"Medium\",\"No\"],\n",
        "        [\"Sunny\",\"High\",\"Yes\"],\n",
        "        [\"Sunny\",\"Medium\",\"Yes\"],\n",
        "        [\"Rainy\",\"High\",\"No\"],\n",
        "        [\"Overcast\",\"Low\",\"Yes\"],\n",
        "        [\"Overcast\",\"Medium\",\"Yes\"],\n",
        "        [\"Rainy\",\"Low\",\"Yes\"]\n",
        "        ]\n",
        "\n",
        "data = pd.DataFrame(data, columns=[\"Outlook\",\"Wind\",\"target\"])\n",
        "naive_classifier = NaiveBayesClassifier()\n",
        "result = naive_classifier.train_classifier(data)\n",
        "\n",
        "print(result)\n",
        "\n",
        "# Correctness check\n",
        "print(result['Dont Know']['Outlook']['total_count'])"
      ],
      "execution_count": 241,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Yes': {'Outlook': {'Sunny': 4, 'Overcast': 2, 'Rainy': 1, 'total_count': 7}, 'Wind': {'Low': 3, 'Medium': 2, 'High': 2, 'total_count': 7}, 'total_count': 7}, 'No': {'Outlook': {'Rainy': 3, 'Overcast': 2, 'total_count': 5}, 'Wind': {'Medium': 3, 'High': 2, 'total_count': 5}, 'total_count': 5}, 'Dont Know': {'Outlook': {'Overcast': 1, 'total_count': 1}, 'Wind': {'High': 1, 'total_count': 1}, 'total_count': 1}, 'overall': 13}\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOmdS1J9x3-6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = [[\"Sunny\",\"High\"],\n",
        "        [\"Sunny\",\"Low\"],\n",
        "        [\"Overcast\",\"Medium\"],\n",
        "        [\"Rainy\",\"High\"],\n",
        "        [\"Rainy\",\"Low\"],\n",
        "        [\"Overcast\",\"Low\"],\n",
        "        [\"Rainy\",\"Medium\"],\n",
        "        [\"Sunny\",\"Medium\"],\n",
        "        ]\n",
        "# ['Yes', 'Yes', 'No', 'No', 'No', 'No', 'No']\n",
        "\n",
        "\n",
        "predicted = naive_classifier.predict(result,data,[\"Outlook\",\"Wind\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87Fjtlk21m9x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3cafe45a-ddbc-4e18-c83b-ab9c2f9b03bd"
      },
      "source": [
        "print(predicted)"
      ],
      "execution_count": 243,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Yes', 'Yes', 'No', 'No', 'No', 'Yes', 'No', 'Yes']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}